# -*- coding: utf-8 -*-
"""06. Support Vector Machine

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f61kVCX9r9CmG3KLUM8eSNPEEe8SVX_4
"""

from sklearn.datasets import fetch_20newsgroups

groups = fetch_20newsgroups()

import nltk
nltk.download('names')
nltk.download('wordnet')

from nltk.corpus import names
from nltk.stem import WordNetLemmatizer

all_names = set(names.words())
lemmatizer = WordNetLemmatizer()

def clean_text(docs):
  cleaned_docs = []
  for doc in docs:
    lemmatized_list = [ lemmatizer.lemmatize (word.lower())
                        for word in doc.split()
                        if word.isalpha() and word not in all_names ]
    cleaned_docs += [ ' '.join(lemmatized_list) ]
  return cleaned_docs

cleaned_data = clean_text(groups.data)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( cleaned_data,
                                                    groups.target,
                                                    test_size = 0.2,
                                                    random_state = 0)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidfv = TfidfVectorizer(max_features=1000, stop_words='english')
tfidfv_model = tfidfv.fit(X_train)

X_train_vec = tfidfv_model.transform(X_train)
X_test_vec = tfidfv_model.fit_transform(X_test)

from sklearn.svm import SVC
from sklearn.metrics import classification_report

svm = SVC(kernel='linear', C=0.1, random_state = 0)
svm.fit(X_train_vec, y_train)
prediction = svm.predict(X_test_vec)
print(classification_report(y_test, prediction))

